# 运行时管线与核心算法

本文件回答两个核心问题：

1. 每帧到底经历了哪些处理步骤；
2. 为了鲁棒性（遮挡、抖动、重复检测）做了哪些处理。

---

## 1. 总体处理流程（按时序）

主流程位于 `src/app.py`，每帧顺序如下：

1. 读取视频帧；
2. 姿态推理（YOLO pose，默认保留单人）；
3. 全图目标检测/分割（YOLO seg，可按白名单过滤）；
4. 手关键点检测（MediaPipe）；
5. 手关键点时序稳定（左右手一致性 + EMA + 丢帧保持）；
6. 基于手关键点构建 ROI，并在 ROI 内再次分割检测（多 ROI 合并为批量推理）；
7. 全图结果 + ROI 结果合并；
8. 目标后处理（去重 + 跨类冲突抑制）；
9. 目标时序稳定（遮挡保持 + 类别投票）；
10. 手-物接触判定；
11. 动作识别（wave/nod/shake）；
12. 可视化与日志输出。

---

## 2. 为什么引入 ROI

### 2.1 背景问题

在全图推理时，小物体常见问题：

- 像素占比太低，容易漏检；
- 与背景纹理混淆；
- 被手遮挡后轮廓不完整，分类容易漂移。

### 2.2 本项目策略

用“手关键点推导 ROI”，在 ROI 区域执行二次分割检测。
直观上是“把手附近放大看一遍”，尤其对“手持小物体”有效。

此外，运行时会把多个 ROI 合并为一次批量 `predict` 调用，降低逐 ROI 重复调用开销。
若 ROI 内没有任何已知类别检测结果，会触发 unknown 回退逻辑：
基于轮廓提取补一个 `unknown` mask，避免“有轮廓但无标签”时完全漏出。
同时通过 ROI 最大尺寸约束与 ROI 目标面积占比过滤，让 ROI 更聚焦于小物体。

---

## 3. ROI 构建逻辑（`src/vision/hand_roi.py`）

### 3.1 不对称 ROI（重点）

ROI 不是对称框，而是“前向外扩多、后向内扩少”的结构。
前向定义为“手腕/掌根 -> 指尖方向”。

关键计算（简化表达）：

- `outward_extent = base * (forward_shift + 0.5 * context_scale)`
- `inward_extent = base * (inward_shift + 0.5 * inward_scale)`
- `lateral_extent = base * 0.5 * max(1.0, context_scale, inward_scale)`

这保证了：

- 物体大部分在手前方时，ROI 更容易覆盖到；
- 物体底部略微越过手腕时，也有内向补偿，不会完全漏掉。

### 3.2 手方向稳定（避免“向外/向内反复跳”）

为防止方向在相邻帧反向：

- 对方向向量做平滑（`direction_smooth`）；
- 做半球对齐（如果与上一帧夹角 > 90°，自动翻转）。

这个设计可以显著减少“ROI 一会儿向外扩，一会儿向内扩”的视觉抖动。

### 3.3 ROI 鲁棒性增强点

- 截尾外接框（trimmed range）抑制离群点；
- 尺度平滑 + shrink floor 防止 ROI 突然缩小；
- 丢点保持（`hold_frames`）防止关键点短失效导致 ROI 闪烁；
- 左右手重叠合并，避免同一只手被画出两个 ROI。

---

## 4. 手关键点稳定器（`src/vision/hand_stabilizer.py`）

### 4.1 要解决的问题

- 左右手标签抖动（颜色反复跳）；
- 手快速移动时抖动明显；
- 遮挡导致短时丢失；
- 同一只手被识别为两只（双框）。

### 4.2 机制拆解

1. 候选去重：中心距离、IoU、重叠比联合判定；
2. 左右手分配：优先 handedness，其次最近历史轨迹，再次按画面左右；
3. 自适应 EMA：
   - 慢速时平滑更强（稳）；
   - 快速运动时提高 `alpha`（跟手）；
4. 丢帧保持：短时缺失仍延用上一帧；
5. 重叠抑制：高度重叠时主动丢弃疑似重复侧。

---

## 5. 目标后处理：去重 + 冲突抑制（`src/postprocess/object_filter.py`）

### 5.1 同类别去重

判重条件：

- IoU 达阈值，或
- 中心距离足够近且面积比合理，或
- 较小框被较大框高比例覆盖（“整体 + 局部”兜底）。

质量排序优先级：

1. 有 mask 的结果优先；
2. 置信度高优先；
3. 框面积更合理者优先。

### 5.2 跨类别冲突抑制

典型错误：一个完整物体 + 一个局部误分类同时出现。
策略：当两个异类框形成强嵌套冲突时，仅保留更可信者。

判断依据：

- 交叠占小框面积比例；
- 大小框面积比；
- 分数差；
- 小框中心是否落在大框内部。

---

## 6. 目标时序稳定（`src/postprocess/object_temporal.py`）

### 6.1 为什么需要

遮挡场景下，单帧分割结果常见：

- 这一帧是 `cup`，下一帧变 `bottle`，再下一帧又回 `cup`；
- 某几帧直接丢失；
- 框大小和位置抖动。

### 6.2 机制

1. 跨帧匹配（IoU + 中心距离比）；
2. bbox/score EMA 融合；
3. 类别分数累积投票（带衰减），抑制类别乱跳；
4. 允许短时 miss 保持（`hold_frames`）；
5. 输出端再次轻量去重，避免轨迹短时分裂。

这使“接触状态”不再因为单帧漏检而频繁断开。

---

## 7. 接触判定策略（`src/contact/hand_object.py`）

### 7.1 多点位判定（不是只看腕点）

接触点来源：

- 指尖；
- MCP（掌指关节）；
- 腕点；
- 掌心中心；
- 指骨采样点（MCP 到 TIP 连线中间点）。

然后对候选点做空间去重，避免近邻点重复计数虚高。

### 7.2 距离度量

- 优先用 mask（并支持膨胀 expand）；
- 无 mask 时退化到 bbox 距离；
- 命中点数达到 `min_points` 才判定接触。

---

## 8. 白名单联动机制（`src/vision/class_whitelist.py`）

目的：训练和推理使用同一份类别定义，避免维护两份名单。

支持：

- 直接读取 `data.yaml` 根节点 `names`；
- 读取训练配置里的 `data: xxx.yaml` 并跳转；
- `names` 既支持 list 也支持 dict。

结合 `--det-whitelist-mode`：

- `override`：完全采用配置；
- `union`：配置与命令行白名单取并集。

---

## 9. 真实部署时的推荐组合

为了在遮挡场景取得更稳效果，推荐默认开启：

- `--hand-stabilize`
- `--hand-roi-det`
- `--obj-dedup`
- `--obj-conflict-suppress`
- `--obj-temporal`

并在调试阶段开启：

- `--debug`

用叠加信息观察：

- `obj raw / dedup / temporal` 的数量关系；
- `hands raw` 与 `lr` 映射是否稳定；
- ROI 数是否符合预期（单手一般为 1）；
- `ms pose/full/roi/hand/post` 的阶段耗时分布，用于定位 FPS 瓶颈。

可视化默认优先显示分割 `mask` 轮廓；如需 bbox-only 预览，可使用 `--no-draw-mask-edges`。
