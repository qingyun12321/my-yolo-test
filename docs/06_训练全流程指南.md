# 训练全流程指南

本指南覆盖两个训练任务：

1. 物体分割微调（用于手持物体识别 + 白名单联动）；
2. 手关键点训练（可选，用于替换默认手关键点来源）。

---

## 1. 分割训练流程（主流程）

### 1.1 流程总览

1. 准备或标注 COCO JSON；
2. 转换为 YOLO Seg 标签；
3. 配置 `training/configs/segment_data.yaml`；
4. 执行训练脚本（官方语义一致）；
5. 用 `best.pt` 推理并联动白名单。

### 1.2 第一步：标注转换（COCO JSON -> YOLO Seg）

```bash
uv run python tools/datasets/segment/convert_coco_to_yolo_seg.py \
  --labels-dir datasets/coco-json/annotations \
  --save-dir datasets/yolo-seg \
  --cls91to80
```

说明：

- 本脚本封装官方 `convert_coco(use_segments=True)`；
- 若数据已为 YOLO Seg 标签格式，可跳过此步骤。

### 1.3 第二步：编辑数据配置

编辑 `training/configs/segment_data.yaml`：

- `path`: 数据集根目录；
- `train` / `val` / `test`: 图像目录；
- `names`: 类别列表（后续推理白名单将复用这里）。

### 1.4 第三步：训练

```bash
uv run python tools/train/segment/train_segment_objects.py \
  --data training/configs/segment_data.yaml \
  --model models/yolo26n-seg.pt \
  --epochs 100 \
  --imgsz 640 \
  --out models/object-seg-finetuned.pt
```

说明：

- 脚本会打印 `Official-equivalent CLI preview`；
- 参数语义与官方 `yolo segment train ...` 对齐。

### 1.5 第四步：按官方 cfg 机制覆盖参数（可选）

```bash
uv run python tools/train/segment/train_segment_objects.py \
  --data training/configs/segment_data.yaml \
  --model models/yolo26n-seg.pt \
  --cfg training/configs/custom_train.yaml \
  --override batch=8 \
  --override lr0=0.005 \
  --override cos_lr=True
```

优先级（从低到高）：

1. Ultralytics 默认配置；
2. `--cfg` 配置；
3. 脚本显式参数（如 `--epochs`、`--imgsz`）；
4. `--override KEY=VALUE`（最终覆盖）。

### 1.6 第五步：推理联动白名单

```bash
uv run python -m src.app \
  --det-model models/object-seg-finetuned.pt \
  --det-whitelist-config training/configs/segment_data.yaml \
  --det-whitelist-mode override
```

这样可保证“训练类别定义 == 推理白名单”。

---

## 2. 手关键点训练流程（可选）

当默认手关键点表现不够好时，可训练自定义 pose 模型。

### 2.1 下载样例数据（可选）

```bash
uv run python tools/datasets/hand/download_hand_keypoints.py
```

### 2.2 训练

```bash
uv run python tools/train/hand/train_hand_keypoints.py \
  --data datasets/hand-keypoints.yaml \
  --model models/yolo26n-pose.pt \
  --epochs 100 \
  --imgsz 640 \
  --out models/hand-keypoints.pt
```

---

## 3. 训练产物与目录说明

### 3.1 Ultralytics 原始产物

- 默认在 `runs/` 下（除非 `project/name` 被覆盖）；
- 常用文件：
  - `weights/best.pt`
  - `weights/last.pt`
  - `results.csv`
  - `args.yaml`

### 3.2 项目约定产物

- 分割模型拷贝到：`models/object-seg-finetuned.pt`
- 手关键点模型拷贝到：`models/hand-keypoints.pt`

---

## 4. 推荐训练策略（实战）

### 4.1 分割任务

- 先保证类别定义稳定，再扩充难样本；
- 强化遮挡样本：
  - 手遮挡物体；
  - 物体遮挡手；
  - 双手共持同一物体；
  - 物体只露局部。
- 每个类别保留“远景小目标 + 中景 + 近景”三档样本。

### 4.2 数据划分建议

- `train:val:test = 8:1:1`（或 `7:2:1`）；
- 同一段视频相邻帧不要同时落在 train/val，避免泄漏。

### 4.3 训练过程监控

重点观察：

- `mAP50-95`（分割任务主指标）；
- 类别混淆（是否发生常见互相误判）；
- 验证集小目标召回变化。

---

## 5. 与运行参数联动调优

训练后，推理端建议按顺序联调：

1. `--det-whitelist-config`
2. `--conf`
3. `--obj-dedup-*`
4. `--obj-temporal-*`
5. `--hand-roi-*`
6. `--contact-*`

目标是先稳定类别，再稳定轨迹，再精调接触判定。
